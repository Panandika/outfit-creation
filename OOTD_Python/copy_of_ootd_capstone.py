# -*- coding: utf-8 -*-
"""Copy of OOTD CAPSTONE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Gr8vs00TT50Di1oFx_tnnFSJcFpsIlKP

IMPORT LIBRARY YANG DIBUTUHIN
"""

import pandas as pd
import json
import cv2
import numpy as np
import matplotlib.pyplot as plt
import urllib.request
import io
import tensorflow as tf
import os
import glob
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Flatten
from keras.models import Model
from keras.callbacks import EarlyStopping

"""# MOUNT GOOGLE DRIVE"""

# from google.colab import drive
# drive.mount('/content/drive', force_remount=True)

"""#Specify the Base Path to Your Dataset (Kalau Pake akun email yang pertama)"""

# Update this path to the location of your dataset
base_path = 'C:/Berkas Kuliah/SEMESTER 5/Bangkit/Project Plan/OOTD_Python/json_based_images/'

"""Function to load the category mapping from a text file"""

# Function to load the category mapping from a text file
def load_category_mapping(file_path):
    mapping = {}
    with open(file_path, 'r') as file:
        for line in file:
            parts = line.strip().split(' ')
            if len(parts) == 2:
                mapping[int(parts[0])] = parts[1]
    return mapping

"""# Function to check if an outfit matches the specified criteria"""

# Function to check if an outfit matches the specified criteria
def is_valid_outfit(outfit, outfit_type, category_mapping):
    required_items = outfit_type.get('required', [])
    optional_items = outfit_type.get('optional', [])
    items_in_outfit = set(category_mapping.get(id, '') for id in outfit['item_categoryid'].tolist())

    if not all(item in items_in_outfit for item in required_items):
        return False

    optional_count = sum(item in items_in_outfit for item in optional_items)
    return optional_count > 0

"""# Function to load and process each JSON file"""

# Function to load and process each JSON file
def load_and_process_json(file_path, category_mapping):
        with open(file_path) as f:
            data = json.load(f)
        outfits = pd.json_normalize(data, 'items', ['set_id', 'set_url'],
                                    record_prefix='item_')
        return process_outfits(outfits, category_mapping)

"""##Function to process outfits##"""

# Function to process outfits
def process_outfits(outfits, category_mapping):
    valid_outfits = []

    for set_id, outfit in outfits.groupby('set_id'):
        print(f"Processing outfit with set_id: {set_id}")
        categories = [category_mapping.get(id, '') for id in outfit['item_categoryid'].tolist()]
        print(f"Categories in outfit: {categories}")

        # if is_valid_outfit(outfit, outfit_type_1, category_mapping):
        #     print("Valid outfit found (Type 1)")
        #     valid_outfits.append(outfit)
        if is_valid_outfit(outfit, outfit_type_2, category_mapping):
            print("Valid outfit found (Type 2)")
            valid_outfits.append(outfit)
        elif is_valid_outfit(outfit, outfit_type_3, category_mapping):
            print("Valid outfit found (Type 3)")
            valid_outfits.append(outfit)
        elif is_valid_outfit(outfit, outfit_type_4, category_mapping):
            print("Valid outfit found (Type 4)")
            valid_outfits.append(outfit)
        elif is_valid_outfit(outfit, outfit_type_5, category_mapping):
            print("Valid outfit found (Type 5)")
            valid_outfits.append(outfit)
        elif is_valid_outfit(outfit, outfit_type_6, category_mapping):
            print("Valid outfit found (Type 6)")
            valid_outfits.append(outfit)
        # elif is_valid_outfit(outfit, outfit_type_7, category_mapping):
        #     print("Valid outfit found (Type 7)")
        #     valid_outfits.append(outfit)
        elif is_valid_outfit(outfit, outfit_type_8, category_mapping):
            print("Valid outfit found (Type 8)")
            valid_outfits.append(outfit)
        elif is_valid_outfit(outfit, outfit_type_9, category_mapping):
            print("Valid outfit found (Type 9)")
            valid_outfits.append(outfit)
        else:
            print("Invalid outfit")

    if not valid_outfits:
        print("No valid outfits found")
        return pd.DataFrame()
    else:
        return pd.concat(valid_outfits).reset_index(drop=True)

"""# Load the category mapping"""

category_mapping = load_category_mapping('C:/Berkas Kuliah/SEMESTER 5/Bangkit/Project Plan/OOTD_Python/polyvore/category_id.txt')

"""# Define your outfit types using actual category names"""

# Define your outfit types using actual category names
# outfit_type_1 = {'required': ['Dresses', 'Shoes', 'Bags'], 'optional': ['Outerwear']}
outfit_type_2 = {'required': ['Tops'], 'optional': ['Pullover', 'Outerwear']}
outfit_type_3 = {'required': ['T-Shirts'], 'optional': ['Jeans', 'Outerwear']}
outfit_type_4 = {'required': ['Sweaters'], 'optional': ['Jeans', 'Outerwear']}
outfit_type_5 = {'required': ['Jackets'], 'optional': ['Jeans', 'Outerwear']}
outfit_type_6 = {'required': ['Jeans'], 'optional': ['Jeans', 'Outerwear']}
# outfit_type_7 = {'required': ['Suits'], 'optional': ['Jeans', 'Outerwear']}
outfit_type_8 = {'required': ['Pants'], 'optional': ['Jeans', 'Outerwear']}
outfit_type_9 = {'required': ['Shoes'], 'optional': ['Jeans', 'Outerwear']}

"""# File paths for the JSON files

Gabungan Dari Semua json file
"""

json_path = 'C:/Berkas Kuliah/SEMESTER 5/Bangkit/Project Plan/OOTD_Python/polyvore/all_file.json'

"""# Process each dataset"""

filtered_outfits = load_and_process_json(json_path, category_mapping)

"""# Save the datasets"""

filtered_outfits.to_csv('C:/Berkas Kuliah/SEMESTER 5/Bangkit/Project Plan/OOTD_Python/polyvore/filtered_outfits.csv', index=False)

"""#THE IMAGE PROCESSING SECTION"""

# Function to process an image
def process_image(image_path, size=(128, 128)):
    try:
        image = cv2.imread(image_path, cv2.IMREAD_COLOR)

        # Check if image is loaded
        if image is None or image.size == 0:
            print(f"Image not loaded from path: {image_path}")
            return None

        # Resize and normalize the image
        image = cv2.resize(image, size)
        image = image / 255.0
        return image
    except Exception as e:
        print(f"Error processing image path {image_path}: {e}")
        return None

"""## Function to process images from a folder"""

# Function to process images from a folder
def process_images_from_folder(folder_path, size=(128, 128)):
    images = []
    for img_path in glob.glob(folder_path + '/*.jpg'):  # Update extension if different
        processed_image = process_image(img_path, size)
        if processed_image is not None:
            images.append(processed_image)
    return images

"""## Load your dataset"""

# Load your dataset (Assuming you have image URLs in the dataset)
data = pd.read_csv('C:/Berkas Kuliah/SEMESTER 5/Bangkit/Project Plan/OOTD_Python/polyvore/filtered_outfits.csv')  # Update with your dataset

"""## Process images and store them"""

processed_images = {}
for set_id in filtered_outfits['set_id']:  # Ensure 'set_id' column is in your dataset
    image_folder = os.path.join(base_path, set_id)
    images = []
    for img_path in glob.glob(image_folder + '/*.jpg'):  # Update extension if different
        processed_image = process_image(img_path)
        if processed_image is not None:
            images.append(processed_image)
    processed_images[set_id] = images



"""## Visualize the first few processed images"""
#
# # Check if processed_images dictionary is empty
# if not processed_images:
#     print("No images were processed. The processed_images dictionary is empty.")
# else:
#     print(f"Total sets processed: {len(processed_images)}")
#
# # Visualize a few processed images with debugging
# for set_id, images in processed_images.items():
#     if not images:
#         print(f"No images found for set_id {set_id}")
#     else:
#         print(f"Visualizing images for set_id {set_id}, Total images: {len(images)}")
#         for i, image in enumerate(images):
#             if i < 5:  # Adjust the number of images to display per set_id
#                 plt.imshow(image)
#                 plt.title(f'Image {i} from set {set_id}')
#                 plt.show()

"""# Data Splitting Section

## Step 1: Parse JSON File for Labels and Categories
First, parse the all_file.json to create a mapping of set_id to labels and categories:

Modify the determine_label(item) function to use the category mapping for assigning labels. This function will now look up the categoryid of each item in the mapping and return the corresponding category name.
"""

def determine_label(item, category_mapping):
    category_id = item['item_categoryid']
    return category_mapping.get(category_id, 'Unknown')  # Default to 'Unknown' if category_id is not in the mapping

import pandas as pd

csv_file_path = 'C:/Berkas Kuliah/SEMESTER 5/Bangkit/Project Plan/OOTD_Python/polyvore/filtered_outfits.csv'  # Update with the path to your CSV file
filtered_outfits = pd.read_csv(csv_file_path)

"""## Step 2: Combine Processed Images with Labels and Categories
Next, combine the processed images with their corresponding labels and categories

Dengan Likes saja
"""

# Convert 'set_id' in filtered_outfits to string
filtered_outfits['set_id'] = filtered_outfits['set_id'].astype(str)

image_data = []
for set_id, images in processed_images.items():
    outfit_likes = filtered_outfits[filtered_outfits['set_id'] == set_id]['item_likes'].iloc[0]
    for image in images:
        image_data.append((image, outfit_likes))

image_df = pd.DataFrame(image_data, columns=['image', 'likes'])

print(filtered_outfits['set_id'].dtype)
if processed_images:
    first_key = next(iter(processed_images))
    print(type(first_key))

print(image_df.head())

"""## Step 3: Data Splitting
Now, you can split this combined data into training, validation, and test sets:


"""

from sklearn.model_selection import train_test_split

# Splitting the data into training, validation, and test sets
train_val, test = train_test_split(image_df, test_size=0.2, random_state=42)
train, val = train_test_split(train_val, test_size=0.25, random_state=42)

print(train.columns)
print(val.columns)
print(test.columns)

# Convert the image data to a numpy array

train_images = np.stack(train['image'].values)  # Converts a series of image arrays into a single numpy array
val_images = np.stack(val['image'].values)  # Converts a series of image arrays into a single numpy array
test_images = np.stack(test['image'].values)  # Converts a series of image arrays into a single numpy array

# Normalize the images if necessary
train_images = train_images.astype('float32') / 255.0
val_images = val_images.astype('float32') / 255.0
test_images = test_images.astype('float32') / 255.0

# Assuming 'train_labels' contains the labels for the training data
train_labels = train['likes'].values  # Convert labels to numpy array
val_labels = val['likes'].values  # Convert labels to numpy array
test_labels = test['likes'].values  # Convert labels to numpy array


"""TEST"""
def categorize_images(image_folder, json_data, category_mapping, size=(128, 128)):
    categories = {'Tops': [], 'Pants': [], 'Shoes': [], 'T - Shirts': []\
                  , 'Jeans': [], 'Sweaters': [], 'Jackets': []}

    for img_path in glob.glob(image_folder + '/*.jpg'):  # Update extension if different
        print(f"Processing image: {img_path}")  # Check if this line is printed for each image
        image_name = os.path.basename(img_path)
        category_id = json_data.get(image_name)
        category_name = category_mapping.get(category_id, 'Unknown')

        if category_name in categories:
            processed_image = process_image(img_path, size)
            if processed_image is not None:
                print(f"Image processed: {img_path}")
                categories[category_name].append(processed_image)

    return categories

# Process and categorize images

# def load_json_data(json_path):
#     with open(json_path, 'r') as file:
#         return json.load(file)
#
# outfitted = load_json_data(json_path)
#
# # Display a sample outfit and its items
# print("Sample Outfit:", outfitted[0]['name'])
# print("Items in this outfit:")
# for item in outfitted[0]['items']:
#     print(f" - {item['name']} (Category ID: {item['categoryid']})")

# def process_and_categorize_images(outfitted, category_mapping, base_image_folder, size=(128, 128)):
#     categorized_images = {'Tops': [], 'Pants': [], 'Shoes': [], 'T - Shirts': []\
#                             , 'Jeans': [], 'Sweaters': [], 'Jackets': []}  # Adjust categories as needed
#
#     for outfit in outfitted:
#         set_id = outfit['set_id']
#         outfit_folder = os.path.join(base_image_folder, set_id)
#
#         for item in outfit['items']:
#             category_id = item['categoryid']
#             category_name = category_mapping.get(category_id, 'Unknown')
#
#             if category_name in categorized_images:
#                 # Process each image in the outfit folder
#                 for img_path in glob.glob(os.path.join(outfit_folder, '*.jpg')):
#                     processed_image = process_image(img_path, size)
#                     if processed_image is not None:
#                         categorized_images[category_name].append(processed_image)
#
#     return categorized_images
#
# categorized_images = process_and_categorize_images(outfitted, category_mapping, base_path)

# Number of samples in the training set
print("Number of samples in training set:", train.shape[0])

# Number of samples in the validation set
print("Number of samples in validation set:", val.shape[0])

# Number of samples in the testing set
print("Number of samples in testing set:", test.shape[0])
#
# # Keperluan Multi Input CNN
# print("Sample JSON data:", list(outfitted.items())[:5])
# print("Sample category mapping:", list(category_mapping.items())[:5])
#
#
#
# # Convert categorized images to numpy arrays
# train_tops = np.array(categorized_images['Tops']) if 'Tops' in categorized_images else np.array([])
# train_pants = np.array(categorized_images['Pants']) if 'Bottoms' in categorized_images else np.array([])
# train_tshirts= np.array(categorized_images['T - Shirts']) if 'Shoes' in categorized_images else np.array([])
# train_shoes = np.array(categorized_images['Shoes']) if 'Shoes' in categorized_images else np.array([])
# train_jeans = np.array(categorized_images['Jeans']) if 'Jeans' in categorized_images else np.array([])
# train_sweaters = np.array(categorized_images['Sweaters']) if 'Sweaters' in categorized_images else np.array([])
# train_jackets = np.array(categorized_images['Jackets']) if 'Jackets' in categorized_images else np.array([])
# #train_suits = np.array(categorized_images['Suits']) if 'Suits' in categorized_images else np.array([])
#
# min_length = min(len(train_tops), len(train_pants), len(train_tshirts), len(train_shoes)\
#                  , len(train_jeans), len(train_sweaters), len(train_jackets), len(train_suits))
#
# print(f"Number of Tops: {len(train_tops)}")
# print(f"Number of Pants: {len(train_pants)}")
# print(f"Number of T Shirt: {len(train_tshirts)}")
# print(f"Number of Shoes: {len(train_shoes)}")
# print(f"Number of Jackets: {len(train_jackets)}")
# print(f"Number of Jeans: {len(train_jeans)}")
# print(f"Number of Sweaters: {len(train_sweaters)}")
# #print(f"Number of Suits: {len(train_suits)}")
#
# train_tops = train_tops[:min_length]
# train_pants = train_pants[:min_length]
# train_tshirts = train_tshirts[:min_length]
# train_shoes = train_shoes[:min_length]
# train_jackets = train_jackets[:min_length]
# train_jeans = train_jeans[:min_length]
# train_sweaters = train_sweaters[:min_length]
# #train_suits = train_suits[:min_length]





"""# **Dimensionality Reduction With an Autoencoder Model**

## Define the Autoencoder Model
"""

from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D
from tensorflow.keras.models import Model

def create_autoencoder(input_shape):
    input_img = Input(shape=input_shape)

    # Encoder
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    encoded = MaxPooling2D((2, 2), padding='same')(x)

    # Decoder
    x = Conv2D(128, (3, 3), activation='relu', padding='same')(encoded)
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)

    autoencoder = Model(input_img, decoded)
    encoder = Model(input_img, encoded)

    autoencoder.summary()
    encoder.summary()

    return autoencoder, encoder

"""## Define the Multi-Input CNN Model"""

from tensorflow.keras.layers import concatenate, Dense, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import RMSprop, Adam


def create_cnn(input_shape, num_outputs):
    # Input Layer
    input_img = Input(shape=input_shape)

    # Convolutional Layers
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
    x = MaxPooling2D((2, 2))(x)
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = MaxPooling2D((2, 2))(x)
    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = MaxPooling2D((2, 2))(x)

    # Flatten and Fully Connected Layers
    x = Flatten()(x)
    x = Dense(512, activation='relu')(x)
    x = Dense(124, activation='relu')(x)
    x = Dense(64, activation='relu')(x)
    output = Dense(num_outputs, activation='linear')(x)  # Use 'softmax' for classification


    model = Model(input_img, output)
    model.summary()

    return model

"""## Train the Autoencoder"""

input_shape = (128, 128, 3) # Define the input shape of your images
autoencoder, encoder = create_autoencoder(input_shape)
print("Model returned from function.")

# Before fitting, confirm the model summary

optimizer = RMSprop(learning_rate=0.09)
autoencoder.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])

#Making EarlyStopping
from tensorflow.keras.callbacks import EarlyStopping

early_stopping_callback = EarlyStopping(
    monitor='val_loss',     # The metric to monitor, e.g., validation loss
    min_delta=0.001,        # Minimum change to qualify as an improvement
    patience=10,            # How many epochs to wait before stopping
    verbose=1,              # Log level
    mode='auto',            # Direction of improvement ('auto', 'min', or 'max')
    restore_best_weights=True # Whether to restore model weights from the epoch with the best value of the monitored quantity
)


autoencoder.fit(train_images, train_images,
                epochs=1,
                batch_size=32,
                verbose=1,
                validation_data=(val_images, val_images),
                callbacks=[early_stopping_callback])
''''## BARUUUU'''

autoencoder_train_data = autoencoder.predict(train_images)
autoencoder_val_data = autoencoder.predict(val_images)
autoencoder_test_data = autoencoder.predict(test_images)


print("predictions autoencoder_train_data shape:", autoencoder_train_data.shape)
print("predictions autoencoder_train_data:", autoencoder_train_data)


input_shapes = (128, 128, 3) # Define the input shapes for each branch
num_outputs = 1    # For likes prediction
cnn = create_cnn(input_shapes, num_outputs)

optimizer_adam = Adam(learning_rate=0.05)

cnn.compile(optimizer=optimizer_adam, loss='mean_squared_error', metrics='accuracy')
cnn.fit(autoencoder_train_data, train_labels,
        epochs=2,
        batch_size=32,
        validation_data=(autoencoder_val_data, val_labels),
        callbacks=[early_stopping_callback])



"""## Evaluate the Models"""

autoencoder.evaluate(test_images, test_images)
cnn_result = cnn.evaluate(autoencoder_test_data, test_labels,
                          batch_size=32)
print("test loss, test acc:", cnn_result)


"""## Save and Convert the Model for TensorFlow Lite (Optional)"""

# Save the model
cnn.save('cnn.h5')

# Convert the model to TensorFlow Lite
converter = tf.lite.TFLiteConverter.from_keras_model(cnn)
tflite_model = converter.convert()

# Save the TFLite model
with open('cnn.tflite', 'wb') as f:
    f.write(tflite_model)


